{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8498657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b2bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source=pd.DataFrame(columns=[\"id\",\"original_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d78e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('cail2022/train_source.json', 'r', encoding='utf-8'):\n",
    "    content = json.loads(line[:-1]) # 将字符串数据转为字典\n",
    "    idx = len(df_source) \n",
    "    df_source.loc[idx,\"id\"]= content[\"pid\"] \n",
    "    df_source.loc[idx,\"original_text\"] = content[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3d1b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23136</td>\n",
       "      <td>基于上述证据,确认如下事实:原告于2012年2月17日至被告处工作,每月工资为3,200元</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22507</td>\n",
       "      <td>同时，姚建杰自述中建二局未曾与其签订劳动合同，未为其缴纳过社会保险，其就是到工地打工，没有档案</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20120</td>\n",
       "      <td>公司将于7月25日连同李华生6月26-7月25日及另外10天工资一起打至李华生的账户上</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21151</td>\n",
       "      <td>诉讼中，原告王伟提供了下列证据：1、请假申请表3份，用以证明其向被告提出了请假一个月的申请，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5214</td>\n",
       "      <td>具体收费标准由市物价、财政、市容园林部门按照国家规定并根据我市实际情况制定。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                      original_text\n",
       "0  23136      基于上述证据,确认如下事实:原告于2012年2月17日至被告处工作,每月工资为3,200元\n",
       "1  22507    同时，姚建杰自述中建二局未曾与其签订劳动合同，未为其缴纳过社会保险，其就是到工地打工，没有档案\n",
       "2  20120        公司将于7月25日连同李华生6月26-7月25日及另外10天工资一起打至李华生的账户上\n",
       "3  21151  诉讼中，原告王伟提供了下列证据：1、请假申请表3份，用以证明其向被告提出了请假一个月的申请，...\n",
       "4   5214             具体收费标准由市物价、财政、市容园林部门按照国家规定并根据我市实际情况制定。"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_source.head()  # 查看内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "006f5a9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_target=pd.DataFrame(columns=[\"id\",\"wrong_ids\",\"edits\",\"pos\",\"offset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bdc757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('cail2022/train_label.json', 'r', encoding='utf-8'):\n",
    "    content = json.loads(line[:-1])  # 将字符串数据转为字典\n",
    "    idx = len(df_target)\n",
    "    df_target.loc[idx,\"id\"]= content[\"pid\"]\n",
    "    if len(content[\"target\"])==0:  # 对于没有错误的数据，wrong_ids为空\n",
    "        df_target.loc[idx,\"wrong_ids\"]=[]\n",
    "    else:\n",
    "        wrong_ids = []  # 初始化位置列表\n",
    "        edit_dic = []  # 初始化修正字典\n",
    "        pos_lst = []  # 记录下错误开始的位置，用于替换\n",
    "        offset_lst = []  # 记录修正后原文字数的变化，用edit-ori\n",
    "        \n",
    "        for x in content[\"target\"]: \n",
    "            start = int(x[\"pos\"])  # 记录出错的文本位置\n",
    "            if len(x[\"ori\"])>1:  # 需要把词语拆成单字记录位置\n",
    "                wrong_ids.append(start)\n",
    "                wrong_ids.append(start+1)\n",
    "            else:\n",
    "                wrong_ids.append(start)\n",
    "            edit_dic.append((x['ori'],x['edit']))  # 记录修改内容\n",
    "            pos_lst.append(start)  # 记录下错误开始的位置 \n",
    "            offset_lst.append(len(x['edit'])-len(x['ori'])) # 记录修正后原文字数的变化   \n",
    "       \n",
    "        df_target.loc[idx,\"wrong_ids\"]= wrong_ids\n",
    "        df_target.loc[idx,\"edits\"]= edit_dic\n",
    "        df_target.loc[idx,\"pos\"] = pos_lst\n",
    "        df_target.loc[idx,\"offset\"] = offset_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a0864f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>wrong_ids</th>\n",
       "      <th>edits</th>\n",
       "      <th>pos</th>\n",
       "      <th>offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23136</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22507</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20120</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21151</td>\n",
       "      <td>[588]</td>\n",
       "      <td>[(评, 凭)]</td>\n",
       "      <td>[588]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5214</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id wrong_ids     edits    pos offset\n",
       "0  23136        []       NaN    NaN    NaN\n",
       "1  22507        []       NaN    NaN    NaN\n",
       "2  20120        []       NaN    NaN    NaN\n",
       "3  21151     [588]  [(评, 凭)]  [588]    [0]\n",
       "4   5214        []       NaN    NaN    NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.head()  # 查看内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2666aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_source, df_target, how='inner', on=\"id\")  # 将source和target拼接到一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c4770e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3000 entries, 0 to 2999\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             3000 non-null   object\n",
      " 1   original_text  3000 non-null   object\n",
      " 2   wrong_ids      3000 non-null   object\n",
      " 3   edits          1426 non-null   object\n",
      " 4   pos            1426 non-null   object\n",
      " 5   offset         1426 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 164.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()  # 查看相应信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51cced6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"correct_text\"] = df[\"original_text\"]  # 生成修改后的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95c137bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if len(df.loc[i,\"wrong_ids\"]) >= 1:  # 对于需要修改的文本\n",
    "        content = df.loc[i,\"correct_text\"]\n",
    "        pos = df.loc[i,\"pos\"]\n",
    "        edits = df.loc[i,\"edits\"]\n",
    "        offset = df.loc[i,\"offset\"]\n",
    "    \n",
    "        if len(pos) == 1:\n",
    "            change_len = len(edits[0][0])  # 改变的文本长度\n",
    "            content = content[:pos[0]]+edits[0][1]+content[pos[0]+change_len:]  # 如果只有一处错误，直接替换即可\n",
    "        else:\n",
    "            for j in range(len(pos)):\n",
    "                change_len = len(edits[j][0])  # 改变的文本长度\n",
    "                if j==0:  # 第一次替换时，不必考虑偏移值\n",
    "                    content = content[:pos[j]]+edits[j][1]+content[pos[j]+change_len:]\n",
    "                else:  # 其他情况下，需要考虑替换文本对文字位置产生的影响，要在位置中加上偏移值\n",
    "                    content = content[:pos[j]+offset[j-1]]+edits[j][1]+content[pos[j]+change_len+offset[j-1]:]  \n",
    "    \n",
    "        df.loc[i,\"correct_text\"]=content   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c548d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "longs=[]\n",
    "for i in range(3000):\n",
    "    if len(df.loc[i,\"original_text\"]) != len(df.loc[i,\"correct_text\"]): # macbert要求必须相同长度\n",
    "        df.drop(index=i,inplace=True)\n",
    "    elif len(df.loc[i,\"original_text\"]) > 512 or len(df.loc[i,\"correct_text\"]) > 512: # 最大长度不能超过512\n",
    "        longs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bf5aeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 195, 1122, 1157, 2718, 2748]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be072930",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in longs:\n",
    "    if len(df.loc[i,\"wrong_ids\"]) == 0:\n",
    "        #print(i)\n",
    "        df.drop(index=i,inplace=True)  # 如果没有错误，则直接过滤掉\n",
    "    else:\n",
    "        # print(len(df.loc[i,\"original_text\"])-df.loc[i,\"wrong_ids\"][0])\n",
    "        # 如果有错误，则从第一处错误开始，寻找该处错误所在的句子的起始位置\n",
    "        # 否则，则直接找到最大限度（倒数第511个字）开始切分\n",
    "        for k in range(df.loc[i,\"wrong_ids\"][0],len(df.loc[i,\"original_text\"])-513,-1):\n",
    "            if df.loc[i,\"original_text\"][k] in [\"。\",\"；\",\"）\",\":\"] or k == len(df.loc[i,\"original_text\"])-512:\n",
    "                # print(k)\n",
    "                # print(df.loc[i,\"wrong_ids\"])\n",
    "                df.loc[i,\"wrong_ids\"]=[x-k-1 for x in df.loc[i,\"wrong_ids\"]]\n",
    "                df.loc[i,\"pos\"] = [x-k-1 for x in df.loc[i,\"pos\"]]\n",
    "                df.loc[i,\"original_text\"]=df.loc[i,\"original_text\"][k+1:]\n",
    "                df.loc[i,\"correct_text\"]=df.loc[i,\"correct_text\"][k+1:]\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5543e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "737dd5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2675 entries, 0 to 2674\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             2675 non-null   object\n",
      " 1   original_text  2675 non-null   object\n",
      " 2   wrong_ids      2675 non-null   object\n",
      " 3   edits          1103 non-null   object\n",
      " 4   pos            1103 non-null   object\n",
      " 5   offset         1103 non-null   object\n",
      " 6   correct_text   2675 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 146.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a801ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 将数据切分成训练数据、测试数据和验证数据，比例为6:3:1\n",
    "lst = list(range(2675))\n",
    "random.shuffle(lst)\n",
    "data = [[] for _ in range(3)]  #分别存储训练数据、测试数据和验证数据\n",
    "for i in range(2675):\n",
    "    k = lst[i] \n",
    "    if 0<=i<1605:\n",
    "        data[0].append({'id': df.loc[k,\"id\"], 'original_text': df.loc[k,\"original_text\"]\n",
    "                           , 'wrong_ids': df.loc[k,\"wrong_ids\"], 'correct_text': df.loc[k,\"correct_text\"]})\n",
    "    elif 1605<=i<2408:\n",
    "        data[1].append({'id': df.loc[k,\"id\"], 'original_text': df.loc[k,\"original_text\"]\n",
    "                           , 'wrong_ids': df.loc[k,\"wrong_ids\"], 'correct_text': df.loc[k,\"correct_text\"]})\n",
    "    else:\n",
    "        data[2].append({'id': df.loc[k,\"id\"], 'original_text': df.loc[k,\"original_text\"]\n",
    "                           , 'wrong_ids': df.loc[k,\"wrong_ids\"], 'correct_text': df.loc[k,\"correct_text\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bd4fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, json_path, mode='w', encoding='utf-8'):\n",
    "    dir = os.path.dirname(os.path.abspath(json_path))\n",
    "    if not os.path.exists(dir):\n",
    "        print(dir)\n",
    "        os.makedirs(dir)\n",
    "    with open(json_path, mode=mode, encoding=encoding) as f:\n",
    "        f.write(json.dumps(data, ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07cde13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[\"train\",\"test\",\"dev\"]\n",
    "for i in range(3):\n",
    "    save_json(data[i],\"cail2022/output/{}.json\".format(name[i])) #将其存储起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd59a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
